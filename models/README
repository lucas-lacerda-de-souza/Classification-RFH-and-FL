🧠Models

This folder contains all model implementations used in the Classification of Reactive Follicular Hyperplasia (RFH) and Follicular Lymphoma (FL) project.
It includes deep learning, multimodal, and classical machine learning architectures for image, clinical, and morphometric data integration.

📘 Model Categories
1. Multimodal Deep Learning

These scripts combine histopathological image features with clinical variables to improve diagnostic performance.

             Script                    │     Level     │                            **Description**
multimodal_alexnet_patch_level.py	   │     Patch     │       AlexNet architecture for patch-level multimodal fusion.
multimodal_alexnet_patient_level.py	   │    Patient    │         Aggregated patient-level model using mean feature pooling.
multimodal_resnet18_patch_level.py	   │     Patch     │   ResNet18-based model integrating local image patches and tabular data.
multimodal_resnet18_patient_level.py   │    Patient    │         ResNet18 model trained on patient-level aggregated embeddings.
multimodal_vgg16_patch_level.py	       │     Patch     │       VGG16 model for multimodal feature learning at the patch level.
multimodal_vgg16_patient_level.py	   │    Patient    │         VGG16 architecture applied at patient-level granularity.


All multimodal models include:
Late fusion between CNN features and clinical embeddings
Weighted loss functions for class imbalance
ROC/PR curve generation
Support for multi-GPU training (torch.nn.DataParallel)

2. Image Segmentation
Script	Description
segmentation_unet++.py	Implements U-Net++ with attention gates for tissue segmentation. 
This segmentation model is used to generate tissue masks for patch extraction and preprocessing.

3. Classical Machine Learning
Script	Description
xgboost_classification_cpc_mpa.py	XGBoost classifier trained on clinicopathologic and morphometric parameters.
xgboost_classification_gradcam.py	XGBoost model trained on Grad-CAM-derived features for interpretability and cross-validation.

Both scripts support:
Training/validation/test split
Feature importance plots
Confusion matrix and ROC/PR evaluation
CSV export of results to /results/

⚙️ Usage Example
# Train a multimodal ResNet18 model (patch-level)
python multimodal_resnet18_patch_level.py \
  --data_dir ./data/train \
  --val_dir ./data/val \
  --epochs 100 \
  --batch_size 64 \
  --output_dir ./results/resnet18_patch/

# Run XGBoost Grad-CAM analysis
python xgboost_classification_gradcam.py \
  --input ./supplementary_data/supplementary_table_4.xlsx \
  --output ./results/xgboost_gradcam/

📁 Output Structure
results/

├── resnet18_patch/

│   ├── model.pth

│   ├── metrics.csv

│   ├── confusion_matrix.png

│   ├── roc_curve.png

│   └── pr_curve.png

├── unetpp_segmentation/

│   ├── masks/

│   └── training_curves.png

└── xgboost_gradcam/

    ├── feature_importance.png

    ├── shap_summary.png

    └── performance_metrics.csv

⚙️ Model Configuration and Training Details
1. Traditional Machine Learning (XGBoost)
Objective: Binary logistic regression
Boosting rounds: 100
Learning rate: 0.1
Maximum tree depth: 6
Train/test split: 70% / 30%
Evaluation metrics: Accuracy, AUC, F1-score, Precision, Recall
Feature interpretability: SHAP (p < 0.2)

2. Nuclear Segmentation (U-Net++)
Architecture: U-Net++ with attention gates
Framework: PyTorch
Input size: 256 × 256 pixels
Training: NuInsSeg (665 images, ~30,000 annotated nuclei)
Data split: 80% training / 10% validation / 10% test
Optimizer: Adam (learning rate = 1 × 10⁻⁴)
Loss function: Binary Cross-Entropy with Logits
Batch size: 4
Epochs: 50
Precision mode: Mixed (CUDA acceleration)

3. Patch Generation and Pre-processing
Patch size: 299 × 299 pixels
Patch overlap: 20%
Color normalization: Macenko method
Data augmentation: Rotations (90°, 180°, 270°) and Gaussian blur
Data split:
Training: 80% (73 cases, 276,823 patches)
Validation: 10% (9 cases, 32,043 patches)
Test: 10% (8 cases, 31,939 patches)
External validation: 2 cohorts (9 cases each; 22,064 and 22,168 patches)
Final dataset size:
1,384,115 training patches
160,215 validation patches
159,695 test patches

4. Multimodal Deep Learning (CNN + MLP Fusion)
Backbones: AlexNet, VGG16, and ResNet18 (ImageNet pretrained)
Fusion strategy: Late fusion (concatenation of CNN and MLP embeddings)
MLP branch: Fully connected layers with ReLU activation and dropout regularization
Optimizer: AdamW (learning rate = 1 × 10⁻⁴, weight decay = 1 × 10⁻⁴)
Loss function: Weighted Cross-Entropy
Batch size: 64
Computation: Mixed precision (CUDA)
Aggregation (patient-level): Mean of patch-level probabilities

🧬 Reproducibility Notes

Python: 3.12.11
PyTorch: 2.8.0 + CUDA 12.8
GPU: 3 × NVIDIA RTX 3090 (24 GB each)
OS: Ubuntu 20.04 LTS
RAM: 125 GB
Random seeds are fixed (torch, numpy, random) for deterministic behavior.
